{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "twelve-antibody",
   "metadata": {},
   "source": [
    "### Importing data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "naval-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, Input, Activation, Masking\n",
    "from tensorflow.python.keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras import optimizers, initializers, layers\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finished-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./jigsaw-toxic-comment-train.csv.zip')\n",
    "test = pd.read_csv('./test.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advanced-salon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (223549, 8)\n",
      "Test shape: (63812, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape: ' + str(train.shape))\n",
    "print('Test shape: ' + str(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-prompt",
   "metadata": {},
   "source": [
    "### Data Exploration and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "familiar-guyana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crude-morrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content lang\n",
       "0   0  Doctor Who adlı viki başlığına 12. doctor olar...   tr\n",
       "1   1   Вполне возможно, но я пока не вижу необходимо...   ru\n",
       "2   2  Quindi tu sei uno di quelli   conservativi  , ...   it\n",
       "3   3  Malesef gerçekleştirilmedi ancak şöyle bir şey...   tr\n",
       "4   4  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...   tr"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "selected-scene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095657</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.054306</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.050566</td>\n",
       "      <td>0.009470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294121</td>\n",
       "      <td>0.093272</td>\n",
       "      <td>0.226621</td>\n",
       "      <td>0.055431</td>\n",
       "      <td>0.219110</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  223549.000000  223549.000000  223549.000000  223549.000000   \n",
       "mean        0.095657       0.008777       0.054306       0.003082   \n",
       "std         0.294121       0.093272       0.226621       0.055431   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  223549.000000  223549.000000  \n",
       "mean        0.050566       0.009470  \n",
       "std         0.219110       0.096852  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naval-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 223549 entries, 0 to 223548\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             223549 non-null  object\n",
      " 1   comment_text   223549 non-null  object\n",
      " 2   toxic          223549 non-null  int64 \n",
      " 3   severe_toxic   223549 non-null  int64 \n",
      " 4   obscene        223549 non-null  int64 \n",
      " 5   threat         223549 non-null  int64 \n",
      " 6   insult         223549 non-null  int64 \n",
      " 7   identity_hate  223549 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-genius",
   "metadata": {},
   "source": [
    "### Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aquatic-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = train['comment_text'].loc[0]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "embedded-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\[[^]]*\\]', ' ', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "allied-chapel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanationwhy the edits made under my usernam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>morei can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanationwhy the edits made under my usernam...      0   \n",
       "1  000103f0d9cfb60f  d aww  he matches this background colour i m s...      0   \n",
       "2  000113f07ec002fd  hey man  i m really not trying to edit war  it...      0   \n",
       "3  0001b41b1c6bb37e   morei can t make any real suggestions on impr...      0   \n",
       "4  0001d958c54c6e35  you  sir  are my hero  any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'] = train['comment_text'].apply(lambda x: clean_text(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funky-administration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>doctor who adl  viki ba l   na   doctor olarak...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>quindi tu sei uno di quelli   conservativi    ...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>malesef ger ekle tirilmedi ancak   yle bir  ey...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>resim seldabagcan jpg resminde kaynak sorunu ...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content lang\n",
       "0   0  doctor who adl  viki ba l   na   doctor olarak...   tr\n",
       "1   1                                                ...   ru\n",
       "2   2  quindi tu sei uno di quelli   conservativi    ...   it\n",
       "3   3  malesef ger ekle tirilmedi ancak   yle bir  ey...   tr\n",
       "4   4   resim seldabagcan jpg resminde kaynak sorunu ...   tr"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['content'] = test['content'].apply(lambda x: clean_text(x))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quick-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = text.split()\n",
    "    text = [word for word in text if not word in set(stopwords.words('english'))]\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = [lem.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "synthetic-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "raising-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'] = train['comment_text'].apply(lambda x: clean_text(x))\n",
    "test['content'] = test['content'].apply(lambda x: clean_text(x))\n",
    "train.to_csv('clean_train.csv')\n",
    "test.to_csv('clean_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "continental-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train['comment_text']\n",
    "test_df = test['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-afghanistan",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-eight",
   "metadata": {},
   "source": [
    "Steps for the Model:\n",
    "- Tokenize\n",
    "- Pad\n",
    "- Create Model\n",
    "- Fit the Model\n",
    "- Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "palestinian-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 200\n",
    "tokenizer = Tokenizer(num_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "multiple-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "\n",
    "tokenizer.fit_on_texts(train_df)\n",
    "X_train_token = tokenizer.texts_to_sequences(train_df)\n",
    "\n",
    "tokenizer.fit_on_texts(test_df)\n",
    "X_test_token = tokenizer.texts_to_sequences(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "religious-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223549, 200) (63812, 200)\n"
     ]
    }
   ],
   "source": [
    "# Pad\n",
    "\n",
    "X_train = pad_sequences(X_train_token, maxlen = maxlen, padding = 'post')\n",
    "X_test  = pad_sequences(X_test_token, maxlen = maxlen, padding = 'post')\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "certified-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "targets = train[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "determined-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "model = Sequential([Input(shape=(maxlen, )),\n",
    "                    Embedding(max_features, 128, mask_zero = True),\n",
    "                    LSTM(64, return_sequences = True, dropout = 0.2),\n",
    "                    GlobalMaxPool1D(),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(64, activation = 'relu'),\n",
    "                    Dropout(0.2),\n",
    "                    Dense(6, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "closed-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "reserved-theta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200, 64)           49408     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 2,613,958\n",
      "Trainable params: 2,613,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ambient-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6288/6288 [==============================] - 1224s 195ms/step - loss: 0.2221 - accuracy: 0.7978 - val_loss: 0.2203 - val_accuracy: 0.9200\n",
      "Epoch 2/3\n",
      "5137/6288 [=======================>......] - ETA: 4:56 - loss: 0.2186 - accuracy: 0.7114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a4b1d2c6b0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     callbacks = [monitor])\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor = 'val_loss', \n",
    "                        min_delta = 1e-3, \n",
    "                        patience = 5, verbose = 1, \n",
    "                        restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train, targets,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 3, validation_split = 0.1,\n",
    "                    callbacks = [monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'], '')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Change of Accuracy over Epochs')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'], '')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Change of Loss over Epochs')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-interface",
   "metadata": {},
   "source": [
    "### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "light-sleep",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7cafc0bac049>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import model_from_json, load_model\n",
    "\n",
    "model.save('toxicity_model.h5')\n",
    "\n",
    "# Save Weights + Architecture\n",
    "model.save_weights('toxicity_model_weights.h5')\n",
    "with open('toxicity_model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-queensland",
   "metadata": {},
   "source": [
    "### Test on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "altered-notebook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.4.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (2.4.1)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.19.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.13.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.36.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.11.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow==2.4.1) (51.1.2.post20210112)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.25.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.0)\n",
      "Requirement already satisfied: keras==2.4.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (2.4.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from keras==2.4.0) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from keras==2.4.0) (5.3.1)\n",
      "Requirement already satisfied: h5py in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from keras==2.4.0) (2.10.0)\n",
      "Requirement already satisfied: tensorflow>=2.2.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from keras==2.4.0) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from keras==2.4.0) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.5.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.13.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.32.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.3.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.11.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow>=2.2.0->keras==2.4.0) (51.1.2.post20210112)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/sparshbohra/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4.0) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tensorflow==2.4.1'\n",
    "!pip install 'keras==2.4.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinated-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('./server/models/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "studied-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "photographic-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stuck-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\[[^]]*\\]', ' ', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    comment_tokens = tokenizer.tokenize(text)\n",
    "    return comment_tokens\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stemmer=PorterStemmer()\n",
    "    words=[]\n",
    "\n",
    "    for word in text:\n",
    "        if(word not in stopwords.words('english')):\n",
    "            stem_word=stemmer.stem(word)\n",
    "            words.append(stem_word)\n",
    "    return words\n",
    "\n",
    "def output_prediction(text, max_features = 22000, maxlen = 200):\n",
    "    tokenizer=Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    tokenized_train=tokenizer.texts_to_sequences(text)\n",
    "    x_train=pad_sequences(tokenized_train,maxlen=maxlen)\n",
    "    if len(x_train) == 0:\n",
    "        return {\n",
    "            \"error\" : \"Not Found\"\n",
    "        }\n",
    "    prediction=model.predict(x_train)\n",
    "    prediction = np.sum(prediction, axis=0)\n",
    "    result = []\n",
    "    for i, value in enumerate(prediction):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if value > 0.05:\n",
    "            result.append(CLASSES[i]) \n",
    "    return {\"result\" : result if len(result) != 0 else [CLASSES[0]]}\n",
    "\n",
    "def text_analysis(text):\n",
    "    cleaned_text_data = clean_text(text)\n",
    "    preprocessed_data = remove_stopwords(cleaned_text_data)\n",
    "    return output_prediction(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "blind-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"bitch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "numeric-vegetation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': ['toxic']}\n"
     ]
    }
   ],
   "source": [
    "print(text_analysis(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "distinguished-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toxic']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "toxicity = text_analysis(test)\n",
    "output = json.dumps(toxicity)\n",
    "output2 = json.loads(output)\n",
    "\n",
    "print(output2['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
